---
layout: post
title:  "Kafka Batch ì²˜ë¦¬ & DB ìµœì í™”"
date:   2025-06-19 22:50:00 +0900
categories: dev
---

# ë“¤ì–´ê°€ë©´ì„œ 

ì‹¤ë¬´ë¥¼ ì§„í–‰í•˜ë©´ì„œ ì„œë²„ ê°„ì˜ ë¹ˆë²ˆí•œ ìš”ì²­ì„ Kafkaë¥¼ ì´ìš©í•´ì„œ ë¬¶ì–´ì„œ ìš”ì²­ì„ ë³´ë‚´ë„ë¡ ì ìš©í•  ì¼ì´ ìƒê²¼ë‹¤. 
ê¸°ì¡´ì— ë¹„ìŠ·í•œ ìƒ˜í”Œì´ ìˆì–´ì„œ, ê·¸ ë¶€ë¶„ì„ ì°¸ê³ í•´ì„œ ìƒ˜í”Œ ì˜ˆì‹œë¥¼ ë§Œë“¤ì–´ ë³¸ë‹¤. 

# Kafka ë°°ì¹˜ ì²˜ë¦¬ í•µì‹¬ ì •ë¦¬

| êµ¬ë¶„                 | ê°œë… & ì„¤ì • í•µì‹¬                                                                                                                                                                                                                                         | ì‹¤ìŠµÂ·ìš´ì˜ íŒ                                                                                            |
| ------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- |
| **Batch Listener** | *Consumer*ê°€ `poll()` ì‹œ ê°€ì ¸ì˜¨ \*\*ë ˆì½”ë“œ ëª©ë¡(List)\*\*ì„ í•œ ë²ˆì— ì• í”Œë¦¬ì¼€ì´ì…˜ìœ¼ë¡œ ì „ë‹¬.<br>Spring-KafkaëŠ”<br>`factory.setBatchListener(true)` + `@KafkaListener` ë©”ì„œë“œ íŒŒë¼ë¯¸í„°ë¥¼ `List<ConsumerRecord<â€¦>>` ë¡œ ì„ ì–¸í•˜ë©´ ë.                                                           | ë‹¨ìˆœ ë£¨í”„Â·bulk SQLÂ·ë²¡í„° ê³„ì‚°ì²˜ëŸ¼ **ì—¬ëŸ¬ ê±´ì„ í•œ ë²ˆì— ì²˜ë¦¬**í•  ë•Œ ìœ ë¦¬.                                                    |
| **Batch í¬ê¸°**       | `max.poll.records` *(default 500)*<br>â†’ poll í•œ ë²ˆì— ë°›ì„ **ìµœëŒ€ ë ˆì½”ë“œ ìˆ˜**.<br>`fetch.min.bytes` & `fetch.max.wait.ms` ë¡œ â€œë©”ì‹œì§€ë¥¼ ì¡°ê¸ˆ ëª¨ì•„ì„œ ë³´ë‚´ ë‹¬ë¼â€ëŠ” íŒíŠ¸ë¥¼ ë¸Œë¡œì»¤ì— ì¤„ ìˆ˜ ìˆìŒ.                                                                                              | â€¢ í•œ ë°°ì¹˜ê°€ ë„ˆë¬´ í¬ë©´ ë©”ëª¨ë¦¬Â·DB lock ê¸¸ì–´ì§.<br>â€¢ ë„ˆë¬´ ì‘ìœ¼ë©´ poll/commit ì™•ë³µì´ ëŠ˜ì–´ TPS ë‚­ë¹„.                              |
| **Ack ì „ëµ**         | *Spring-Kafka* ì»¨í…Œì´ë„ˆ ì†ì„±<br>`AckMode`<br>â€£ **BATCH** (ê¸°ë³¸) : ë¦¬ìŠ¤ë„ˆ ë¦¬í„´ ì‹œ ë°°ì¹˜ ì „ì²´ ì»¤ë°‹<br>â€£ **MANUAL(\_IMMEDIATE)** : ì• í”Œë¦¬ì¼€ì´ì…˜ì´ `Acknowledgment.acknowledge()` í˜¸ì¶œí•´ì•¼ ì»¤ë°‹                                                                                          | MANUAL ëª¨ë“œ + ì¬ì‹œë„/ì—ëŸ¬í•¸ë“¤ëŸ¬ ì¡°í•©í•˜ë©´ **exactly-once like** í”Œë¡œìš° ì„¤ê³„ ê°€ëŠ¥                                         |
| **ìˆœì°¨ vs ë³‘ë ¬**       | - Partition ë‹¨ìœ„ ìˆœì„œëŠ” Kafkaê°€ ë³´ì¥<br>- í•˜ë‚˜ì˜ Consumer Thread(concurrency = 1)ê°€ ì—¬ëŸ¬ Partitionì„ ìˆœì°¨ ì²˜ë¦¬í•˜ë©´ **TPS ìƒí•œ = ë‹¨ì¼ ìŠ¤ë ˆë“œ ì²˜ë¦¬ëŸ‰**<br>- TPS í™•ì¥ = `partition ìˆ˜ â†‘` + `concurrency ìˆ˜ â†‘`                                                                            | CPU-bound ì‘ì—…ì€ ì½”ì–´ ìˆ˜ë§Œí¼ concurrency ëŠ˜ë¦¬ë©´ ì„ í˜• í™•ì¥. DB-bound ëŠ” Batch insertÂ·ì»¤ë„¥ì…˜ í’€ í¬ê¸°ë„ ê°™ì´ ê³ ë ¤                |

## docker-compose.yml

``` yml
version: "3.8"

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1
    ports: ["2181:2181"]
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.6.1
    depends_on: [zookeeper]
    ports: ["9092:9092"]
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
```

## application.yml

``` yml

spring:
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      group-id: test-group
      properties:
        max.poll.records: 500
      auto-offset-reset: earliest
    listener:
      type: batch
      concurrency: 1

```

## topic ì´ˆê¸°í™” shell

``` shell
docker compose exec kafka kafka-topics \
  --delete --topic test-topic \
  --bootstrap-server localhost:9092

docker compose exec kafka kafka-topics \
  --create --topic test-topic \
  --partitions 16 --replication-factor 1 \
  --bootstrap-server localhost:9092
```


## KafkaConfig.java
concurrencyë¥¼ 1ë¡œ ì„¤ì •í•´ì„œ ìˆœì°¨ì ìœ¼ë¡œ polling í•˜ë„ë¡ í•¨

``` java

@EnableKafka
@Configuration
public class KafkaConfig {

    private static final String BOOTSTRAP = "localhost:9092";

    /* ---------- Producer ---------- */
    @Bean
    public ProducerFactory<String, String> producerFactory() {
        return new DefaultKafkaProducerFactory<>(Map.of(
                org.apache.kafka.clients.producer.ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP,
                org.apache.kafka.clients.producer.ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,
                org.apache.kafka.common.serialization.StringSerializer.class,
                org.apache.kafka.clients.producer.ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
                org.apache.kafka.common.serialization.StringSerializer.class
        ));
    }

    @Bean
    public KafkaTemplate<String, String> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }

    /* ---------- Consumer ---------- */
    @Bean
    public ConsumerFactory<String, String> consumerFactory() {
        return new DefaultKafkaConsumerFactory<>(Map.of(
                ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP,
                ConsumerConfig.GROUP_ID_CONFIG, "test-group",
                ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class,
                ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class,
                ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "false",
                ConsumerConfig.MAX_POLL_RECORDS_CONFIG, "500"
        ));
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory() {
        var factory = new ConcurrentKafkaListenerContainerFactory<String, String>();
        factory.setConsumerFactory(consumerFactory());
        factory.setBatchListener(true);
        factory.setConcurrency(1);
        factory.getContainerProperties()
                .setAckMode(ContainerProperties.AckMode.MANUAL);
        return factory;
    }
}

```


# Case 1. 16ê°œì˜ íŒŒí‹°ì…˜ì— ê°ê° 100ê±´ì˜ ë°ì´í„°ê°€ ìˆê³ , ì´ë¥¼ concurrency 1ë¡œ ì²˜ë¦¬í•˜ëŠ” ë°©ì‹

max poll records ê°¯ìˆ˜ë¥¼ 500ê±´ìœ¼ë¡œ ì„¤ì •í–ˆìœ¼ë¯€ë¡œ, 1600ê±´ì˜ ë°ì´í„° ì¤‘ì—ì„œ ìµœëŒ€ 500ê±´ì”© ë‚˜ëˆ ì„œ polling í•˜ê²Œëœë‹¤.

> **DemoConsumer**

``` java

@Component
public class DemoConsumer {

    @KafkaListener(topics = "${demo.topic:test-topic}", containerFactory = "kafkaListenerContainerFactory")
    public void listen(List<ConsumerRecord<String, String>> records, Acknowledgment ack) {

        System.out.printf("ğŸ“¥ polled %d records%n", records.size());

        Map<Integer, Long> byPartition = records.stream()
                .collect(Collectors.groupingBy(ConsumerRecord::partition, Collectors.counting()));
        byPartition.forEach((p, c) -> System.out.printf("  â€¢ partition %d â†’ %d%n", p, c));

        ack.acknowledge();
    }
}

```

> **DemoProducer**

``` java

@Component
public class DemoProducer {

    private final KafkaTemplate<String, String> kafkaTemplate;

    @Value("${demo.topic:test-topic}")
    private String topic;

    public DemoProducer(KafkaTemplate<String, String> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

    @PostConstruct
    public void sendMessages() {
        for (int p = 0; p < 16; p++) {
            for (int i = 0; i < 100; i++) {
                String value = "msg-part" + p + "-num" + i;
                kafkaTemplate.send(topic, p, null, value);
            }
        }
        System.out.println("âœ… 1600 ê±´ ì „ì†¡ ì™„ë£Œ");
    }
}

```

**í…ŒìŠ¤íŠ¸ ê²°ê³¼**

```
2025-06-19T23:16:57.740+09:00  INFO 9250 --- [ad | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 3 with epoch 0
âœ… 1600 ê±´ ì „ì†¡ ì™„ë£Œ

...

2025-06-19T23:17:01.351+09:00  INFO 9250 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions assigned: [test-topic-0, test-topic-1, test-topic-2, test-topic-3, test-topic-4, test-topic-5, test-topic-6, test-topic-7, test-topic-8, test-topic-9, test-topic-10, test-topic-11, test-topic-12, test-topic-13, test-topic-14, test-topic-15]
ğŸ“¥ polled 500 records
  â€¢ partition 10 â†’ 100
  â€¢ partition 12 â†’ 100
  â€¢ partition 13 â†’ 100
  â€¢ partition 14 â†’ 100
  â€¢ partition 15 â†’ 100
ğŸ“¥ polled 500 records
  â€¢ partition 6 â†’ 100
  â€¢ partition 7 â†’ 100
  â€¢ partition 8 â†’ 100
  â€¢ partition 9 â†’ 100
  â€¢ partition 11 â†’ 100
ğŸ“¥ polled 500 records
  â€¢ partition 0 â†’ 100
  â€¢ partition 2 â†’ 100
  â€¢ partition 3 â†’ 100
  â€¢ partition 4 â†’ 100
  â€¢ partition 5 â†’ 100
ğŸ“¥ polled 100 records
  â€¢ partition 1 â†’ 100


```


# Case 2. ì§€ì†ì ìœ¼ë¡œ 1~1000 ì‚¬ì´ì˜ ë°ì´í„° ìŒ“ì¼ë•Œ concurrency 1ë¡œ ì²˜ë¦¬í•˜ëŠ” ì¼€ì´ìŠ¤

``` java

package dev.rumble.kafkatest.component;

import org.springframework.beans.factory.annotation.Value;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;

import java.util.Random;

@Component
public class RandomProducer {

    private final KafkaTemplate<String, String> kafkaTemplate;
    private final Random random = new Random();

    public RandomProducer(KafkaTemplate<String, String> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }
    @Value("${demo.topic:test-topic}")
    private String topic;

    @Scheduled(fixedDelay = 500)
    public void randomSend() {
        int msgs = 1 + random.nextInt(1_000);  // [1, 1 000]
        int partCnt = 16;

        for (int i = 0; i < msgs; i++) {
            int p = i % partCnt;               // round-robin íŒŒí‹°ì…˜
            kafkaTemplate.send(topic, p, null, "rnd-" + System.nanoTime());
        }
        System.out.println("â–¶ï¸  produced {} records" + msgs);
    }

}


```

**í…ŒìŠ¤íŠ¸ ê²°ê³¼**

``` 
ğŸ“¥ polled 500 records
  â€¢ partition 2 â†’ 127
  â€¢ partition 4 â†’ 5
  â€¢ partition 5 â†’ 368
ğŸ“¥ polled 500 records
  â€¢ partition 2 â†’ 241
  â€¢ partition 3 â†’ 259
ğŸ“¥ polled 500 records
  â€¢ partition 0 â†’ 368
  â€¢ partition 1 â†’ 23
  â€¢ partition 3 â†’ 109
ğŸ“¥ polled 345 records
  â€¢ partition 1 â†’ 345
â–¶ï¸  produced {} records305
ğŸ“¥ polled 3 records
  â€¢ partition 14 â†’ 3
ğŸ“¥ polled 302 records
  â€¢ partition 0 â†’ 20
  â€¢ partition 1 â†’ 19
  â€¢ partition 2 â†’ 19
  â€¢ partition 3 â†’ 19
  â€¢ partition 4 â†’ 19
  â€¢ partition 5 â†’ 19
  â€¢ partition 6 â†’ 19
  â€¢ partition 7 â†’ 19
  â€¢ partition 8 â†’ 19
  â€¢ partition 9 â†’ 19
  â€¢ partition 10 â†’ 19
  â€¢ partition 11 â†’ 19
  â€¢ partition 12 â†’ 19
  â€¢ partition 13 â†’ 19
  â€¢ partition 14 â†’ 16
  â€¢ partition 15 â†’ 19
```

AWSì˜ Firehose ì²˜ëŸ¼ íŠ¹ì • ì‹œê°„ í˜¹ì€ pollingí•  ë°ì´í„° ì‚¬ì´ì¦ˆ í¬ê¸°ì— ë”°ë¼ì„œ ì•„ë˜ì™€ ê°™ì€ ì„¸íŒ…ë„ ê°€ëŠ¥í•˜ë‹¤.

``` java

@Component
public class DemoConsumer {

    private static final int THRESHOLD = 500;            // ê±´ìˆ˜ ì¡°ê±´
    private static final long MAX_INTERVAL_MS = 1_000;   // ì‹œê°„ ì¡°ê±´

    private final List<ConsumerRecord<String, String>> buffer = new ArrayList<>();
    private long lastFlush = System.currentTimeMillis();

    private final Logger log = LoggerFactory.getLogger(getClass());

    @KafkaListener(
            topics = "${demo.topic:test-topic}",
            containerFactory = "kafkaListenerContainerFactory")
    public void listen(List<ConsumerRecord<String, String>> batch,
                       Acknowledgment ack) {

        buffer.addAll(batch);

        long now = System.currentTimeMillis();
        boolean readyBySize  = buffer.size() >= THRESHOLD;
        boolean readyByTime  = now - lastFlush >= MAX_INTERVAL_MS;

        if (readyBySize || readyByTime) {
            flushBuffer(now);
            ack.acknowledge();     // í•œêº¼ë²ˆì— ì»¤ë°‹
        }
    }

    private void flushBuffer(long now) {
        log.info("ğŸ”¥ flush {} records ({} ms since last)",
                buffer.size(), now - lastFlush);

        buffer.stream()
                .collect(Collectors.groupingBy(ConsumerRecord::partition,
                        Collectors.counting()))
                .forEach((p, c) -> log.info("  â€¢ partition {} â†’ {}", p, c));

        buffer.clear();
        lastFlush = now;
    }
}



```

**í…ŒìŠ¤íŠ¸ ê²°ê³¼** 

ì•„ë˜ì™€ ê°™ì´ 500ê±´ì´ polling ê°€ëŠ¥í•˜ë©´ pollingì‹œí‚¤ê³ , 1ì´ˆê°€ ì§€ë‚˜ë©´ ë‚¨ì•„ìˆëŠ” ìˆ«ìë¥¼ pollingí•œë‹¤.

``` 
2025-06-19T23:38:04.825+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     : ğŸ”¥ flush 500 records (5 ms since last)
2025-06-19T23:38:04.825+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 0 â†’ 170
2025-06-19T23:38:04.825+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 1 â†’ 9
2025-06-19T23:38:04.825+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 2 â†’ 153
2025-06-19T23:38:04.825+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 3 â†’ 168
â–¶ï¸  produced {} records116
â–¶ï¸  produced {} records57
â–¶ï¸  produced {} records164
2025-06-19T23:38:06.234+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     : ğŸ”¥ flush 379 records (1409 ms since last)
2025-06-19T23:38:06.234+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 0 â†’ 15
2025-06-19T23:38:06.234+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 1 â†’ 175
2025-06-19T23:38:06.234+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 2 â†’ 14
2025-06-19T23:38:06.234+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 3 â†’ 14
2025-06-19T23:38:06.234+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 4 â†’ 15
2025-06-19T23:38:06.234+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 5 â†’ 15
2025-06-19T23:38:06.234+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 6 â†’ 14
2025-06-19T23:38:06.234+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 7 â†’ 14
2025-06-19T23:38:06.234+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 8 â†’ 14
2025-06-19T23:38:06.234+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 9 â†’ 13
2025-06-19T23:38:06.234+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 10 â†’ 13
2025-06-19T23:38:06.234+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 11 â†’ 13
2025-06-19T23:38:06.235+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 12 â†’ 13
2025-06-19T23:38:06.235+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 13 â†’ 13
2025-06-19T23:38:06.235+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 14 â†’ 12
2025-06-19T23:38:06.235+09:00  INFO 12034 --- [ntainer#0-0-C-1] d.r.kafkatest.component.DemoConsumer     :   â€¢ partition 15 â†’ 12
â–¶ï¸  produced {} records227

```

# DB ìµœì í™”

## SQL Query ì‘ì„± ì‹œ Subqueryì™€ Joinì˜ ì°¨ì´ì 

subqueryëŠ” ì¡°ê±´ì„ í™•ì¸í• ë•Œ ì í•© (í•„í„°ë§ë§Œ í•˜ê³  í•˜ë‚˜ì˜ í…Œì´ë¸”ì—ì„œë§Œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ë„ ë ë• Subquery)
joinì€ ë³µì¡í•œ Projectionì„ í• ë•Œ ì í•©

## Nested Loops Joinì˜ ê²½ìš° O(N^2)ë¡œ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•ŠìŒ
=> ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Hash Joinì„ ì‚¬ìš© (MySQL 5.7ë¶€í„° ì§€ì›)
Hash Joinì€ ë‘ í…Œì´ë¸”ì„ í•´ì‹œ í…Œì´ë¸”ë¡œ ë§Œë“¤ì–´ì„œ ì¡°ì¸í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ, O(N) ì„±ëŠ¥ì„ ë³´ì¥

DBì˜ í†µê³„ë¥¼ ì´ìš©í•´ì„œ ë°ì´í„° ë¶„í¬ë‚˜ í¬ê¸°ë¥¼ íŒŒì•…í•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì ì˜ ì¡°ì¸ ìˆœì„œë¥¼ ê²°ì •í•˜ëŠ” ê²ƒì´ ì¤‘ìš”

ì¤‘ì²© ë£¨í”„ëŠ” ê°€ì¥ ê°„ë‹¨í•œ ì¡°ì¸ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, ë‘ í…Œì´ë¸”ì˜ ëª¨ë“  ì¡°í•©ì„ ë¹„êµí•˜ì—¬ ì¼ì¹˜í•˜ëŠ” í–‰ì„ ì°¾ëŠ” ë°©ì‹

## Hash Join 
í•´ì‹œ ì¡°ì¸ì€ ë‘ë‹¨ê³„ë¡œ ì´ë£¨ì–´ì§
1. í•´ì‹œë§µ, í•´ì‹œ í…Œì´ë¸”ì„ ìƒì„±í•œë‹¤. (ë²„í‚· ê¸°ë°˜ìœ¼ë¡œ ì‘ë™) (ì‹¤í–‰ê³„íš ì‹œ Hash Semi Join ì´ëŸ° ì‹ìœ¼ë¡œ ë‚˜ì˜´)
    -> í•´ì‹œê°’ì„ ì´ìš©í•´ì„œ ê²€ì¦ 
    -> ë¹„êµì  ìš”ì†Œê°€ ì ì€ ê²ƒì„ ì´ìš©í•´ì„œ ë§µì„ ìƒì„± (ë©”ëª¨ë¦¬ ì–‘ì„ ì¤„ì¼ ìˆ˜ ìˆìŒ)
2. iterateí•˜ë©´ì„œ í•´ì‹œë§µì— ìˆëŠ” ê°’ì„ ì°¾ëŠ”ë‹¤.
    -> í•´ì‹œë§µì— ìˆëŠ” ê°’ê³¼ ë¹„êµí•´ì„œ ì¼ì¹˜í•˜ëŠ” ê°’ì„ ì°¾ëŠ”ë‹¤. (ìˆœì°¨ ë£¨í”„)

-> ì´ìƒì ìœ¼ë¡œ ê°€ì¥ ì‘ì€ ë¹„ìš©ìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤.

## Megered Join
1. í…Œì´ë¸” ì •ë ¬ (ì¸ë±ìŠ¤ê°€ ìˆì„ë•Œ ì´ ì•Œê³ ë¦¬ì¦˜ì„ ì„ íƒí•˜ê³ , B+ ì¸ë±ìŠ¤ëŠ” ì •ë ¬ëœ êµ¬ì¡°ì´ë‹¤.)
2. ë‘ í…Œì´ë¸”ì„ ìˆœíšŒí•˜ë©´ì„œ ê°™ì€ ì»¨ë””ì…˜ì¸ ê²ƒì„ ì²´í¬í•œë‹¤. (MySQLì€ ë¯¸ì§€ì›)

Order Byê°€ ìˆìœ¼ë©´ ê°™ì´ ì‚¬ìš©
O(nLog(N))ì˜ ì„±ëŠ¥ì„ ë³´ì¥
